{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b05fcd05",
   "metadata": {},
   "source": [
    "## Question and Answer ##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d730d4",
   "metadata": {},
   "source": [
    "\n",
    "- Given a piece of text, maybe extracted from a PDF file or from a webpage or from some company's intranet internal document collection, can you use an LLM to answer questions about the content of those documents to help users gain a deeper understanding and get access to the information that they need? \n",
    "    - This is really powerful because it starts to combine these language models with data that they weren't originally trained on. \n",
    "    - it makes them much more flexible and adaptable to your use case. \n",
    "    - It's also really exciting because we'll start to move beyond language models, prompts, and output parsers and start introducing some more of the key components of LangChain, such as **embedding models and vector stores.** \n",
    " \n",
    "- **embeddings and vector stores** \n",
    "    - are some of the most powerful modern techniques, \n",
    "        - import the retrieval QA chain. This will do retrieval over some documents. \n",
    "        - import our favorite chat open AI language model. \n",
    "        - import a document loader. \n",
    "            - This is going to be used to load some proprietary data that we're going to combine with the language model. \n",
    "            - import a vector store. \n",
    "                - There are many different types of vector stores we're going to get started with the \"DocArrayInMemorySearch\" vector store. \n",
    "                    - it's an in-memory vector store and it doesn't require connecting to an external database of any kind so it makes it really easy to get started. \n",
    "            - import display and markdown to common utilities for displaying information in Jupyter notebooks. \n",
    "            - import an index, the \"VectorStoreIndexCreator\". \n",
    "                - This will help us create a vector store really easily. \n",
    "                - To create it, we're going to specify two things. \n",
    "                    - First, we're going to specify the vector store class. \n",
    "                        - After it's been created, we're then going to call \"from_loaders\", which takes in a list of document loaders. \n",
    "                        - We've only got one loader that we really care about, so that's what we're passing in here. \n",
    "        - It's now been created and we can start to ask questions about it. \n",
    "\n",
    "\n",
    "    - We've gotten back a table in markdown with names and descriptions for all shirts with sun protection. \n",
    "    - We've also got a summary that the language model has provided us. \n",
    "- So we've gone over how to do question answering over your documents, but what exactly is going on underneath the hood? \n",
    "    - First, let's think about the general idea. \n",
    "        - We want to use language models and combine it with a lot of our documents. \n",
    "        - But there's a key issue. \n",
    "            - Language models can only inspect a few thousand words at a time. \n",
    "                - So if we have really large documents, how can we get the language model to answer questions about everything that's in there? \n",
    "                - This is where embeddings and vector stores come into play. \n",
    "                    - First, let's talk about embeddings. \n",
    "                        - **Embeddings create numerical representations for pieces of text.** \n",
    "                        - This numerical representation captures the semantic meaning of the piece of text that it's been run over. \n",
    "                        - Pieces of text with similar content will have similar vectors. \n",
    "                            - This lets us compare pieces of text in the vector space. \n",
    "                            - In the example below, we can see that we have three sentences. The first two are about pets, while the third is about a car. \n",
    "                            - If we look at the representation in the numeric space, we can see that when we compare the two vectors on the pieces of text corresponding to the sentences about pets, they're very similar. \n",
    "\n",
    "                        - This will let us easily figure out which pieces of text are like each other, which will be very useful as we think about which pieces of text we want to include when passing to the language model to answer a question. \n",
    "                    - The next component that we're going to cover is the vector database. \n",
    "                        - A vector database is a way to store these vector representations that we created in the previous step. \n",
    "                        - The way that we create this vector database is we populate it with chunks of text coming from incoming documents. \n",
    "                        - When we get a big incoming document, we're first going to break it up into smaller chunks. This helps create pieces of text that are smaller than the original document, which is useful because we may not be able to pass the whole document to the language model. \n",
    "                        - So we want to **create these small chunks so we can only pass the most relevant ones to the language model.** \n",
    "                        - We then create an embedding for each of these chunks, and then we store those in a vector database. That's what happens when we **create the index.**\n",
    "                        - Now that we've got this index, we can use it during runtime to find the pieces of text most relevant to an incoming query. \n",
    "                        - When a query comes in, we \n",
    "                            - **first create an embedding for that query.** \n",
    "                            - We then **compare it to all the vectors in the vector database**, and we pick the n most similar. \n",
    "                            - These are then returned, and we can pass those in the prompt to the language model to get back a final answer. \n",
    "                    - So above, we created this chain and only a few lines of code. That's great for getting started quickly. \n",
    "            - Let's now do it a bit more step-by-step and understand what exactly is going on under the hood. \n",
    "                - The first step is similar to above. \n",
    "                    - We're going to create a document loader, loading from that CSV with all the descriptions of the products that we want to do question answering over. We can then load documents from this document loader. \n",
    "                        - If we look at the individual documents, we can see that each document corresponds to one of the products in the CSV. \n",
    "                    - Because these documents are already so small, we actually don't need to do any chunking here. And so we can create embeddings directly. \n",
    "                - To create embeddings, we're going to use OpenAI's embedding class. \n",
    "                    - We can import it and initialize it here. \n",
    "                    \n",
    "- how do we use this to do question answering over our own documents? \n",
    "    - First, we need to **create a retriever from this vector store**. \n",
    "        - A retriever is **a generic interface** that can be **underpinned by any method** that takes in a query and returns documents. Vector stores and embeddings are one such method to do so, \n",
    "    - Next, because we want to do text generation and return a natural language response, we're going to import a language model and we're going to use ChatOpenAI. \n",
    "        - If we were doing this by hand, we would combine the documents into a single piece of text. where we **join all the page content in the documents into a variable**\n",
    "        - and then pass this variable or a variant on the question, like, \"Please list all your shirts with sun protection in a table in markdown and summarize each one.\" into the language model. \n",
    "    - All of those steps can be encapsulated with the LangChain chain. \n",
    "    \n",
    "- we can **create a retrieval QA chain.**\n",
    "    - This does retrieval and then does question answering over the retrieved documents. To create such a chain, we'll pass in a few different things. \n",
    "        - First, we'll pass in the language model. \n",
    "            - This will be used for doing the text generation at the end. \n",
    "        - Next, we'll **pass in the chain type**. We're going to use `\"stuff\"`. \n",
    "            - This is the simplest method as it just `stuffs all the documents into context and makes one call to a language model`. \n",
    "            - There are a few other methods that you can use to do question answering \n",
    "        - Third, we're going to pass in a retriever. \n",
    "            - The retriever we created above is just `an interface for fetching documents.` \n",
    "            - This will be used to fetch the documents and pass it to the language model. \n",
    "        - finally, we're going to set \"verbose=True\". \n",
    "    - Now, we can create a query and we can run the chain on this query. \n",
    "        - but remember that we can still do it pretty easily with just the one line that we had up above. \n",
    " \n",
    "- the interesting stuff about LangChain. \n",
    "    - You can do it in one line, \n",
    "    - or you can look at the individual things and break it down into five more detailed ones. \n",
    "        - The five more detailed ones let you set more specifics about what exactly is going on, but the one-liner is easy to get started. \n",
    "        \n",
    "- We can also **customize the index when we're creating it**. \n",
    "    - specified an embedding. this will give us flexibility over how the embeddings themselves are created. \n",
    "    - we can also swap out the vector store here for a different type of vector store. \n",
    "    - We use the \"stuff method\" in this notebook. \n",
    "        - The stuff method is pretty simple. You just **put all of it into one prompt** and send that to the language model and get back one response. So it's quite simple to understand what's going on. \n",
    "        - It's quite cheap and it works pretty well. \n",
    "        - But that doesn't always work okay. \n",
    "            - when we fetched the documents in the notebook, we only got four documents back and they were relatively small. \n",
    "            - what if you wanted to do the same type of question answering over lots of different types of chunks? \n",
    "                - there are a few different methods that we can use. \n",
    "                    - \"Map_reduce\". This basically takes all the chunks, passes them along with the question to a language model, gets back a response, and then uses another language model call to summarize all of the individual responses into a final answer. \n",
    "                        - This is really powerful because it can operate over any number of documents. \n",
    "                        - And it's also really powerful because you can do the individual questions in parallel. \n",
    "                        - But it does take a lot more calls. \n",
    "                        - And it does treat all the documents as independent, which may not always be the most desired thing. \n",
    "                        - a really common use case of the \"Map_reduce\" chain is for summarization, where you have a really long document and you want to recursively summarize pieces of information in it. \n",
    "                    - \"Refine\", which is another method, is again used to loop over many documents. but it actually does it iteratively. \n",
    "                        - It builds upon the answer from the previous document. \n",
    "                        - So this is really good for combining information and building up an answer over time. \n",
    "                        - It will generally lead to longer answers. \n",
    "                        - it's also not as fast because now the calls aren't independent. They depend on the result of previous calls. This means that it often takes a good while longer and takes just as many calls as \"Map_reduce\", basically. \n",
    "                    - \"Map_rerank\" is a pretty interesting and a bit more experimental one where you do a single call to the language model for each document. And you also ask it to return a score. then you select the highest score. \n",
    "                        - This relies on the language model to know what the score should be. So you often have to tell it, \"Hey, it should be a high score if it's relevant to the document and really refine the instructions there\". \n",
    "                        - Similar to \"Map_reduce\", all the calls are independent. So you can batch them and it's relatively fast. \n",
    "                        - But again, you're making a bunch of language model calls. So it will be a bit more expensive. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3007d4e",
   "metadata": {},
   "source": [
    "### LangChain: Q&A over Documents ###\n",
    "An example might be a tool that would allow you to query a product catalog for items of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d803017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY']='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e636413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81462c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89be1fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "167dcbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'OutdoorClothingCatalog_1000.csv'\n",
    "loader = CSVLoader(file_path=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1950b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "253e3d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install docarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f33e24f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73be2896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorstore=<langchain.vectorstores.docarray.in_memory.DocArrayInMemorySearch object at 0x7fc11b499df0>\n"
     ]
    }
   ],
   "source": [
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd389699",
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"Please list all your shirts with sun protection \\\n",
    "in a table in markdown and summarize each one.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceb9b08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = index.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2257d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "| Name | Description |\n",
       "| --- | --- |\n",
       "| Men's Tropical Plaid Short-Sleeve Shirt | UPF 50+ rated, 100% polyester, wrinkle-resistant, front and back cape venting, two front bellows pockets |\n",
       "| Men's Plaid Tropic Shirt, Short-Sleeve | UPF 50+ rated, 52% polyester and 48% nylon, machine washable and dryable, front and back cape venting, two front bellows pockets |\n",
       "| Men's TropicVibe Shirt, Short-Sleeve | UPF 50+ rated, 71% Nylon, 29% Polyester, 100% Polyester knit mesh, wrinkle resistant, front and back cape venting, two front bellows pockets |\n",
       "| Sun Shield Shirt by | UPF 50+ rated, 78% nylon, 22% Lycra Xtra Life fiber, wicks moisture, fits comfortably over swimsuit, abrasion resistant |\n",
       "\n",
       "All four shirts provide UPF 50+ sun protection, blocking 98% of the sun's harmful rays. The Men's Tropical Plaid Short-Sleeve Shirt is made of 100% polyester and is wrinkle-resistant. The Men's Plaid Trop"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af507bfe",
   "metadata": {},
   "source": [
    "### Step By Step ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47e03452",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "loader = CSVLoader(file_path=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d076626",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81fb1baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\": 0\\nname: Women's Campside Oxfords\\ndescription: This ultracomfortable lace-to-toe Oxford boasts a super-soft canvas, thick cushioning, and quality construction for a broken-in feel from the first time you put them on. \\n\\nSize & Fit: Order regular shoe size. For half sizes not offered, order up to next whole size. \\n\\nSpecs: Approx. weight: 1 lb.1 oz. per pair. \\n\\nConstruction: Soft canvas material for a broken-in feel and look. Comfortable EVA innersole with Cleansport NXT® antimicrobial odor control. Vintage hunt, fish and camping motif on innersole. Moderate arch contour of innersole. EVA foam midsole for cushioning and support. Chain-tread-inspired molded rubber outsole with modified chain-tread pattern. Imported. \\n\\nQuestions? Please contact us for any inquiries.\", metadata={'source': 'OutdoorClothingCatalog_1000.csv', 'row': 0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b29267cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf3eec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = embeddings.embed_query(\"Hi my name is Jessica\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b19c67dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n"
     ]
    }
   ],
   "source": [
    "print(len(embed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bba62d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.033419179780663916, -0.0012581591633956397, -0.012294453683891452, -0.026725462118644336, -0.02017994769318297]\n"
     ]
    }
   ],
   "source": [
    "print(embed[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33c64b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DocArrayInMemorySearch.from_documents(\n",
    "    docs, \n",
    "    embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a93ad5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Please suggest a shirt with sunblocking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a565d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21b60de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35b36269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=': 255\\nname: Sun Shield Shirt by\\ndescription: \"Block the sun, not the fun – our high-performance sun shirt is guaranteed to protect from harmful UV rays. \\n\\nSize & Fit: Slightly Fitted: Softly shapes the body. Falls at hip.\\n\\nFabric & Care: 78% nylon, 22% Lycra Xtra Life fiber. UPF 50+ rated – the highest rated sun protection possible. Handwash, line dry.\\n\\nAdditional Features: Wicks moisture for quick-drying comfort. Fits comfortably over your favorite swimsuit. Abrasion resistant for season after season of wear. Imported.\\n\\nSun Protection That Won\\'t Wear Off\\nOur high-performance fabric provides SPF 50+ sun protection, blocking 98% of the sun\\'s harmful rays. This fabric is recommended by The Skin Cancer Foundation as an effective UV protectant.', metadata={'source': 'OutdoorClothingCatalog_1000.csv', 'row': 255})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c766672",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbd23d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature = 0.0, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "351daefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdocs = \"\".join([docs[i].page_content for i in range(len(docs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66e2c808",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.call_as_llm(f\"{qdocs} Question: Please list all your \\\n",
    "shirts with sun protection in a table in markdown and summarize each one.\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea936ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Name | Description |\n",
       "| --- | --- |\n",
       "| Sun Shield Shirt | High-performance sun shirt with UPF 50+ sun protection, moisture-wicking, and abrasion-resistant fabric. Fits comfortably over swimsuits. |\n",
       "| Men's Plaid Tropic Shirt | Ultracomfortable shirt with UPF 50+ sun protection, wrinkle-free fabric, and front/back cape venting. Made with 52% polyester and 48% nylon. |\n",
       "| Men's TropicVibe Shirt | Men's sun-protection shirt with built-in UPF 50+ and wrinkle-resistant fabric. Features front/back cape venting and two front bellows pockets. |\n",
       "| Men's Tropical Plaid Short-Sleeve Shirt | Lightest hot-weather shirt with UPF 50+ sun protection, relaxed traditional fit, and front/back cape venting. Made with 100% polyester. |\n",
       "\n",
       "All of these shirts provide UPF 50+ sun protection, blocking 98% of the sun's harmful rays. They also have additional features such as moisture-wicking, wrinkle-resistant, and venting for cool breezes. The Sun Shield Shirt is abrasion-resistant and fits comfortably over swimsuits. The Men's Plaid Tropic Shirt is made with a blend of polyester and nylon and is machine washable/dryable. The Men's TropicVibe Shirt is also wrinkle-resistant and has two front bellows pockets. The Men's Tropical Plaid Short-Sleeve Shirt has a relaxed traditional fit and is made with 100% polyester."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b578a38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7fb7ddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query =  \"Please list all your shirts with sun protection in a table \\\n",
    "in markdown and summarize each one.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9508ba3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = qa_stuff.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b745f24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Shirt ID | Name | Description |\n",
       "| --- | --- | --- |\n",
       "| 618 | Men's Tropical Plaid Short-Sleeve Shirt | Rated UPF 50+ for superior protection from the sun's UV rays. Made of 100% polyester and is wrinkle-resistant. With front and back cape venting that lets in cool breezes and two front bellows pockets. |\n",
       "| 374 | Men's Plaid Tropic Shirt, Short-Sleeve | Rated to UPF 50+ and offers sun protection. Made with 52% polyester and 48% nylon, this shirt is machine washable and dryable. Additional features include front and back cape venting, two front bellows pockets. |\n",
       "| 535 | Men's TropicVibe Shirt, Short-Sleeve | Built-in UPF 50+ has the lightweight feel you want and the coverage you need when the air is hot and the UV rays are strong. Made with 71% Nylon, 29% Polyester. Wrinkle-resistant. Front and back cape venting lets in cool breezes. Two front bellows pockets. |\n",
       "| 255 | Sun Shield Shirt | High-performance sun shirt is guaranteed to protect from harmful UV rays. Made with 78% nylon, 22% Lycra Xtra Life fiber. Fits comfortably over your favorite swimsuit. Abrasion-resistant. |\n",
       "\n",
       "The Men's Tropical Plaid Short-Sleeve Shirt is made of 100% polyester and is wrinkle-resistant. It is rated UPF 50+ for superior protection from the sun's UV rays. The Men's Plaid Tropic Shirt, Short-Sleeve is made with 52% polyester and 48% nylon, and is rated to UPF 50+. The Men's TropicVibe Shirt, Short-Sleeve has built-in UPF 50+ and is made with 71% Nylon, 29% Polyester. The Sun Shield Shirt is made with 78% nylon, 22% Lycra Xtra Life fiber and is guaranteed to protect from harmful UV rays."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a278d44",
   "metadata": {},
   "source": [
    "- **When run index.query(query, llm=llm)**\n",
    "    - The query (which is usually a string of text) is first converted into an embedding\n",
    "    - Once the embedding for the query is generated, the vector store performs a similarity search. \n",
    "        - This involves comparing the query's embedding to the embeddings stored in the vector store. The comparison is typically based on a similarity metric, such as cosine similarity, Euclidean distance, or other relevant metrics. \n",
    "        - The goal is to find the embeddings in the store that are most similar (or least distant, depending on the metric) to the query's embedding.\n",
    "    - The search results, which are the items from the vector store that have the highest similarity scores with the query embedding, are then returned. \n",
    "        - These results can be in various forms, such as documents, sentences, or any data type that was stored in the vector store alongside their embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9eb6f173",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = index.query(query, llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72edf024",
   "metadata": {},
   "source": [
    "- creating a vector store and also storing embeddings in that vector store.\n",
    "    - VectorstoreIndexCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa45bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch,\n",
    "    embedding=embeddings,\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "718b7b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorstore=<langchain.vectorstores.docarray.in_memory.DocArrayInMemorySearch object at 0x7fc11b752430>\n"
     ]
    }
   ],
   "source": [
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71523622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
