{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "403cfcba",
   "metadata": {},
   "source": [
    "LangChain for large language model application development. \n",
    "\n",
    "- By prompting an LLM or large language model, it is now possible to develop AI applications much faster than ever before. \n",
    "    - An application can require prompting an LLM **multiple times and parsing its output**, and so there's a lot of glue code that needs to be written. \n",
    "    - LangChain makes this development process much easier. \n",
    "        - LangChain started as an open source framework for building LLM applications. when building more complex applications and saw some **common abstractions** in terms of how they were being developed. \n",
    "        - As a sign of LangChain's momentum, not only does it have numerous users, but there are also many hundreds of contributors to the open source, and this has been instrumental for its rapid rate of development. This team really ships code and features at an amazing pace. \n",
    "        \n",
    "- LangChain is an open source development framework for building LLM applications. \n",
    "    - There are two different packages, a Python one and a JavaScript one. \n",
    "    - They're focused on **composition and modularity**.\n",
    "        - they have a lot of individual components that can be used in conjunction with each other or by themselves. that's one of the key value adds.  \n",
    "        - the other key value add is a bunch of different use cases. So chains of combining these modular components into more end-to-end applications making it very easy to get started with those use cases. \n",
    "\n",
    "- in this Chapter:\n",
    "    - **prompts**, which are how you get models to do useful and interesting things. \n",
    "    - **indexes**, which are ways of ingesting data so that you can combine it with models. And \n",
    "    - **chains**, which are more end-to-end use cases along with agents, which are a very exciting type of end-to-end use case which uses the model as a reasoning engine. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dd636d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
